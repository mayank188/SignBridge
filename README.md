# ğŸ¤ SignBridge

SignBridge is an **AI-powered communication bridge** that converts **sign language gestures into text and speech output** in real time.  
It aims to help break communication barriers between the **deaf/mute community** and the **hearing world** using modern machine learning and computer vision technologies.

---

## ğŸš€ Features
- ğŸ–ï¸ Real-time **hand gesture recognition** using MediaPipe and TensorFlow  
- ğŸ§  AI model trained on sign language datasets  
- ğŸ”Š Converts recognized gestures into **text and speech output**  
- ğŸŒ Interactive **3D avatar display** to visualize gestures  
- ğŸ¤ Supports **speech-to-text** for bidirectional communication  
- ğŸ’» Clean UI with a simple and intuitive interface  

---

## ğŸ§  Tech Stack

| Technology | Purpose |
|-------------|----------|
| **Python** | Core AI logic and backend |
| **TensorFlow / Keras** | Machine Learning model for gesture recognition |
| **MediaPipe** | Hand tracking and landmark detection |
| **Flask** | Backend API to connect AI with the frontend |
| **React.js / Three.js** | Frontend interface and 3D avatar visualization |
| **JavaScript / HTML / CSS** | UI design and interactivity |
| **Text-to-Speech (TTS) API** | Converts recognized text into audio speech |

---

## ğŸ—ï¸ System Architecture

1. **User Input** â€” Live video feed captures hand gestures.  
2. **Preprocessing** â€” MediaPipe detects hand landmarks and sends data to the model.  
3. **Model Prediction** â€” TensorFlow model predicts the corresponding sign.  
4. **Output** â€” Flask sends the predicted text to the frontend.  
5. **Speech Generation** â€” Text is converted into spoken words using a TTS engine.  
6. **3D Avatar Display** â€” A 3D avatar mirrors the recognized gestures visually.

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/yourusername/SignBridge.git
cd SignBridge
